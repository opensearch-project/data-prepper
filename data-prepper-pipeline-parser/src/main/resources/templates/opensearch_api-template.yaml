"<<pipeline-name>>":
  workers: "<<$.<<pipeline-name>>.workers>>"
  delay: "<<$.<<pipeline-name>>.delay>>"
  buffer: "<<$.<<pipeline-name>>.buffer>>"
  source:
    opensearch_api: "<<$.<<pipeline-name>>.source.opensearch_api>>"
    acknowledgments: "<<$.<<pipeline-name>>.source.opensearch_api.aws.acknowledgments>>"
    delete_s3_objects_on_read: "<<$.<<pipeline-name>>.source.opensearch_api.aws.delete_s3_objects_on_read>>"
  sink:
    - s3:
        aws:
          region:  "<<$.<<pipeline-name>>.source.opensearch_api.s3_region>>"
          sts_role_arn: "<<$.<<pipeline-name>>.source.opensearch_api.aws.sts_role_arn>>"
#          sts_external_id: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_external_id>>"
#          sts_header_overrides: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_header_overrides>>"
        bucket: "<<$.<<pipeline-name>>.source.opensearch_api.s3_bucket>>"
        threshold:
          event_collect_timeout: "120s"
          maximum_size: "2mb"
        aggregate_threshold:
          maximum_size: "256kb"
          flush_capacity_ratio: 0
        object_key:
          path_prefix: "api/"
        codec:
          event_json:
"<<pipeline-name>>-s3":
    workers: "<<$.<<pipeline-name>>.workers>>"
    delay: "<<$.<<pipeline-name>>.delay>>"
    buffer: "<<$.<<pipeline-name>>.buffer>>"
    source:
      s3:
        codec:
          event_json:
        aws:
          region:  "<<$.<<pipeline-name>>.source.opensearch_api.s3_region>>"
          sts_role_arn: "<<$.<<pipeline-name>>.source.opensearch_api.aws.sts_role_arn>>"
#          sts_external_id: "<<$.<<pipeline-name>>.source.opensearch_api.aws.sts_external_id>>"
#          sts_header_overrides: "<<$.<<pipeline-name>>.source.opensearch_api.aws.sts_header_overrides>>"
        acknowledgments: "<<$.<<pipeline-name>>.source.opensearch_api.aws.acknowledgments>>"
        delete_s3_objects_on_read: "<<$.<<pipeline-name>>.source.opensearch_api.aws.delete_s3_objects_on_read>>"
        scan:
          buckets:
            - bucket:
                name: "<<$.<<pipeline-name>>.source.opensearch_api.s3_bucket>>"
          scheduling:
            interval: "60s"
    processor: "<<$.<<pipeline-name>>.processor>>"
    sink: "<<$.<<pipeline-name>>.sink>>"
    routes: "<<$.<<pipeline-name>>.routes>>"